{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4611f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ef257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5718bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "# using glob to extract all .edf files from the folder\n",
    "\n",
    "all_file_path = glob('data/*.edf')\n",
    "print(len(all_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c72e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\Subject00_1.edf',\n",
       " 'data\\\\Subject00_2.edf',\n",
       " 'data\\\\Subject01_1.edf',\n",
       " 'data\\\\Subject01_2.edf',\n",
       " 'data\\\\Subject02_1.edf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_file_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f671765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 36\n"
     ]
    }
   ],
   "source": [
    "# from data set we already know there are total 36 persons \n",
    "# and each one has two .edf files subjectid_01 for data before arithmetic task\n",
    "# and subjectid_02 for data during arithmetic task\n",
    "# so here i assigned all the files which has 1 after '_' to before_arithmetic_task\n",
    "# similarly all the files that has 2 after '_' to during arithmetic task\n",
    "\n",
    "before_arithmetic_task = [i for i in all_file_path if '1' in i.split('_')[1]]\n",
    "during_arithmetic_task = [i for i in all_file_path if '2' in i.split('_')[1]]\n",
    "\n",
    "print(len(before_arithmetic_task), len(during_arithmetic_task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3e4f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\Subject00_1.edf', 'data\\\\Subject01_1.edf', 'data\\\\Subject02_1.edf', 'data\\\\Subject03_1.edf', 'data\\\\Subject04_1.edf', 'data\\\\Subject05_1.edf', 'data\\\\Subject06_1.edf', 'data\\\\Subject07_1.edf', 'data\\\\Subject08_1.edf', 'data\\\\Subject09_1.edf', 'data\\\\Subject10_1.edf', 'data\\\\Subject11_1.edf', 'data\\\\Subject12_1.edf', 'data\\\\Subject13_1.edf', 'data\\\\Subject14_1.edf', 'data\\\\Subject15_1.edf', 'data\\\\Subject16_1.edf', 'data\\\\Subject17_1.edf', 'data\\\\Subject18_1.edf', 'data\\\\Subject19_1.edf', 'data\\\\Subject20_1.edf', 'data\\\\Subject21_1.edf', 'data\\\\Subject22_1.edf', 'data\\\\Subject23_1.edf', 'data\\\\Subject24_1.edf', 'data\\\\Subject25_1.edf', 'data\\\\Subject26_1.edf', 'data\\\\Subject27_1.edf', 'data\\\\Subject28_1.edf', 'data\\\\Subject29_1.edf', 'data\\\\Subject30_1.edf', 'data\\\\Subject31_1.edf', 'data\\\\Subject32_1.edf', 'data\\\\Subject33_1.edf', 'data\\\\Subject34_1.edf', 'data\\\\Subject35_1.edf']\n"
     ]
    }
   ],
   "source": [
    "print(before_arithmetic_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6000a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\Subject00_2.edf', 'data\\\\Subject01_2.edf', 'data\\\\Subject02_2.edf', 'data\\\\Subject03_2.edf', 'data\\\\Subject04_2.edf', 'data\\\\Subject05_2.edf', 'data\\\\Subject06_2.edf', 'data\\\\Subject07_2.edf', 'data\\\\Subject08_2.edf', 'data\\\\Subject09_2.edf', 'data\\\\Subject10_2.edf', 'data\\\\Subject11_2.edf', 'data\\\\Subject12_2.edf', 'data\\\\Subject13_2.edf', 'data\\\\Subject14_2.edf', 'data\\\\Subject15_2.edf', 'data\\\\Subject16_2.edf', 'data\\\\Subject17_2.edf', 'data\\\\Subject18_2.edf', 'data\\\\Subject19_2.edf', 'data\\\\Subject20_2.edf', 'data\\\\Subject21_2.edf', 'data\\\\Subject22_2.edf', 'data\\\\Subject23_2.edf', 'data\\\\Subject24_2.edf', 'data\\\\Subject25_2.edf', 'data\\\\Subject26_2.edf', 'data\\\\Subject27_2.edf', 'data\\\\Subject28_2.edf', 'data\\\\Subject29_2.edf', 'data\\\\Subject30_2.edf', 'data\\\\Subject31_2.edf', 'data\\\\Subject32_2.edf', 'data\\\\Subject33_2.edf', 'data\\\\Subject34_2.edf', 'data\\\\Subject35_2.edf']\n"
     ]
    }
   ],
   "source": [
    "print(during_arithmetic_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be64404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read the .edf file data using mne package\n",
    "\n",
    "def read_data(file_path):\n",
    "    data = mne.io.read_raw_edf(file_path, preload = True)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(l_freq = 0.5, h_freq = 45)\n",
    "    epochs = mne.make_fixed_length_epochs(data, duration = 5, overlap = 1)\n",
    "    array = epochs.get_data()\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6dbe15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\prave\\Desktop\\eeg-during-mental-arithmetic-tasks\\data\\Subject00_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 3301 samples (6.602 s)\n",
      "\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 2500 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# i just passed a edf file to read_data function to check weather the function is working or not\n",
    "# we can see what information is extracted from the .edf file\n",
    "\n",
    "sample_data = read_data(during_arithmetic_task[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87055e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 21, 2500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the data that we extracted from .edf file\n",
    "sample_data.shape # no of epochs, channels, length of signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b174eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following two lines are needed in order to execute the magic word 'capture'\n",
    "# it function is to capture the cell output and hides it \n",
    "# used to hide the unnecessary info from printing \n",
    "# it has no connection to this project\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a398295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# extract all 36 before_arithmetic_task data into before_epochs_array\n",
    "before_epochs_array = [read_data(i) for i in before_arithmetic_task]\n",
    "\n",
    "# extract all 36 during_arithmetic_task data into during_epochs_array\n",
    "during_epochs_array = [read_data(i) for i in during_arithmetic_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5826709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 21, 2500), (15, 21, 2500))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_epochs_array[0].shape, during_epochs_array[0].shape # no of epochs, channels, length of signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96fda8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 36)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each person data be in the following format\n",
    "# person 1\n",
    "#    epoch 1\n",
    "#    epoch 2\n",
    "#    epoch 3\n",
    "#    ....\n",
    "# person 2\n",
    "#    epoch 1\n",
    "#    epoch 2\n",
    "#    epoch 3\n",
    "#    ....\n",
    "\n",
    "# so we need to create label for each epoch under each person not just one label for one person\n",
    "# the following two lines of code are to create labels for each epoch under each person/each .edf file\n",
    "# 0 for before arithmetic task and 1 for during arithmetic task data\n",
    "\n",
    "before_epochs_labels = [len(i)*[0] for i in before_epochs_array]\n",
    "during_epochs_labels = [len(i)*[1] for i in during_epochs_array]\n",
    "len(before_epochs_labels), len(during_epochs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b69cf0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list is combination of before arithmetic data and during arithmetic data\n",
    "data_list = before_epochs_array + during_epochs_array\n",
    "\n",
    "# label_list is combination of before arithmetic labels and during arithmetic labels\n",
    "label_list = before_epochs_labels + during_epochs_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b88aeda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data based on subjects\n",
    "# not on the basis of epochs or trails\n",
    "# assign a group to each subject(edf file) and split based on groups\n",
    "# because we know the data is in the follwing format\n",
    "# person 1\n",
    "#    epoch 1\n",
    "#    epoch 2\n",
    "#    epoch 3\n",
    "#    ....\n",
    "# person 2\n",
    "#    epoch 1\n",
    "#    epoch 2\n",
    "#    epoch 3\n",
    "#    ....\n",
    "# if we randomly split it based on epochs person1 epoch1 may fall under training data\n",
    "# at the same time person1 epoch2 may fall under test data\n",
    "# now the model would easily predict because it trained on person1 and leads to overfitting\n",
    "\n",
    "# in order to overcome that we assign a group value for each epoch\n",
    "# like person1 group value for each epoch is 1 and person2 group value for each epoch is 2 so on\n",
    "# and then split the data based on groups \n",
    "# now all the epochs on person1 may fall either on train or test not on both\n",
    "group_list = [[i]*len(j) for i,j in enumerate(data_list)]\n",
    "len(group_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbfadc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2132, 21, 2500) (2132,) (2132,)\n"
     ]
    }
   ],
   "source": [
    "# convert lists into numpy arrays\n",
    "data_array = np.vstack(data_list)\n",
    "label_array = np.hstack(label_list)\n",
    "group_array = np.hstack(group_list)\n",
    "print(data_array.shape, label_array.shape, group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b236ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2132, 21)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2132, 21, 2500) --> (no of epochs, channels, length of signal)\n",
    "# if i have to extract only one feature shape --> 2132,21\n",
    "# if i have to extract 2 features --> 2132,21*2 for 10 features --> 2132,21*10\n",
    "# for extracting mean of all features\n",
    "np.mean(data_array, axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4101e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract different features from the data (total 12 features)\n",
    "# here all the features are statistical features \n",
    "# we can also include band wise psd features i include those in eegnet classification file\n",
    "from scipy import stats\n",
    "\n",
    "def mean(x):\n",
    "    return np.mean(x, axis = -1)\n",
    "def std(x):\n",
    "    return np.std(x, axis = -1)\n",
    "def ptp(x):\n",
    "    return np.ptp(x, axis = -1)\n",
    "def var(x):\n",
    "    return np.var(x, axis = -1)\n",
    "\n",
    "def minim(x):\n",
    "    return np.min(x, axis = -1)\n",
    "def maxim(x):\n",
    "    return np.max(x, axis = -1)\n",
    "\n",
    "def argminim(x):\n",
    "    return np.argmin(x, axis = -1)\n",
    "def argmaxim(x):\n",
    "    return np.argmax(x, axis = -1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2, axis = -1))\n",
    "\n",
    "def abs_diff_signal(x):\n",
    "    return np.sum(np.abs(np.diff(x, axis = -1)), axis = -1)\n",
    "\n",
    "def skewness(x):\n",
    "    return stats.skew(x, axis = -1)\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x, axis = -1)\n",
    "\n",
    "def concatenate_features(x):\n",
    "    return np.concatenate((mean(x),std(x),ptp(x),var(x),minim(x),maxim(x),argminim(x),argmaxim(x),\n",
    "                           rms(x),abs_diff_signal(x),skewness(x),kurtosis(x)), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9feed8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for d in data_array:\n",
    "    features.append(concatenate_features(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c77f13b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2132, 252)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenated features shape\n",
    "features_array = np.array(features)\n",
    "features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a194726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "252/21 # we have 21 channels and we took 12 features thats how we get 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92b4f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5205a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression is used because this is a binary classification model\n",
    "# main goal for this project is to classify weather given .edf file data is belongs to a person\n",
    "# who is in rest state i.e before arithmetic task \n",
    "# or task state i.e during arithmetic task\n",
    "# due to the values are too small standard scalar is applied in order to scale the data\n",
    "\n",
    "%%capture\n",
    "clf = LogisticRegression()\n",
    "gkf = GroupKFold(10)\n",
    "pipe = Pipeline([('scalar', StandardScaler()), ('clf', clf)])\n",
    "param_grid = {'clf__C': [0.1,0.5,0.7,1,3,5,7]}\n",
    "gscv = GridSearchCV(pipe, param_grid, cv = gkf, n_jobs = 12)\n",
    "gscv.fit(features_array, label_array, groups = group_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c0b53f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6265647789032649"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf233a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 62.6% accuracy is achieved for logistic regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
